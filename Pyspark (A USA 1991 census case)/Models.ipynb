{"cells":[{"cell_type":"code","source":["from pyspark import *"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":1},{"cell_type":"code","source":["#Step 1: Read the table from the spark data\ncensus = spark.read.table(\"adult_csv\")\n#Step2 : Reading the Table Schema\ncensus.printSchema()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">root\n-- age: integer (nullable = true)\n-- employer_type: string (nullable = true)\n-- numf1: integer (nullable = true)\n-- education: string (nullable = true)\n-- numf2: integer (nullable = true)\n-- marital: string (nullable = true)\n-- occupation: string (nullable = true)\n-- relationship: string (nullable = true)\n-- race: string (nullable = true)\n-- gender: string (nullable = true)\n-- capitalgain: integer (nullable = true)\n-- capitalloss: integer (nullable = true)\n-- hr_per_wk: integer (nullable = true)\n-- region: string (nullable = true)\n-- income: string (nullable = true)\n\n</div>"]}}],"execution_count":2},{"cell_type":"code","source":["#census1 = census\nimport pyspark.sql.functions as F\nstep1 = [F.when(~F.col(x).isin(\"?\",\"NULL\", \"NA\", \"NaN\"), F.col(x)).alias(x)  for x in census.columns] \nstep2 = census.select(*step1).dropna(how='any')\nstep3 = step2.drop('numf1','numf2') \n#numf2 is dropped because its numerical lable for education column so its pointless to have both so i used education\n#numf1 is finalweight and was beyound the comprehension as to how the datat collectors arrived at that(kaggale)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":3},{"cell_type":"code","source":["# normalize my numeric data\n\nfrom pyspark.ml.feature import MinMaxScaler\nfrom pyspark.ml.feature import VectorAssembler\nfrom pyspark.ml import Pipeline\nfrom pyspark.sql.functions import udf\nfrom pyspark.sql.types import DoubleType\n\n# UDF for converting column type from vector to double type\nunlist = udf(lambda x: round(float(list(x)[0]),3), DoubleType())\n\n\n# VectorAssembler Transformation - Converting column to vector type\nassembler = [VectorAssembler(inputCols= [col], outputCol=\"Vect_\"+col) for col in ['capitalgain','capitalloss']]\n# MinMaxScaler Transformation\nscaler = [MinMaxScaler(inputCol=\"Vect_\"+col, outputCol=\"Scaled_\"+col) for col in ['capitalgain','capitalloss'] ]\n\n# Pipeline of VectorAssembler and MinMaxScaler\nall_stages = assembler + scaler \npipeline = Pipeline(stages= all_stages)\n\n# Fitting pipeline on dataframe\nstep4 = pipeline.fit(step3).transform(step3).drop('capitalgain','capitalloss','Vect_capitalgain','Vect_capitalloss').withColumn('Scaled_capitalgain', unlist('Scaled_capitalgain')).withColumn('Scaled_capitalloss', unlist('Scaled_capitalloss'))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":4},{"cell_type":"code","source":["from pyspark.ml.feature import Bucketizer\nfrom pyspark.ml import Pipeline\n#for age\n\nbucketizer_age = Bucketizer(splits=[0.0, 30.0, 45.0, 60.0,float(\"inf\")], inputCol=\"age\", outputCol=\"index_age_group\")\nbucketizer_hrwk = Bucketizer(splits=[0.0, 25.0, 45.0, float(\"inf\")], inputCol=\"hr_per_wk\", outputCol=\"index_hr/wk\")\nbucketizer_cg = Bucketizer(splits=[0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, float(\"inf\")], inputCol=\"Scaled_capitalgain\", outputCol=\"index_capital_gain\")\nbucketizer_cl = Bucketizer(splits=[0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, float(\"inf\")], inputCol=\"Scaled_capitalloss\", outputCol=\"index_capital_loss\")\n# Transform original data into its bucket index.\nstep5 = bucketizer_age.transform(step4).drop(\"age\")\nstep5 = bucketizer_hrwk.transform(step5).drop(\"hr_per_wk\")\nstep5 = bucketizer_cg.transform(step5).drop(\"Scaled_capitalgain\")\nstep5 = bucketizer_cl.transform(step5).drop(\"Scaled_capitalloss\")\nstep5 = step5.withColumnRenamed(\"index_age_group\",\"age\").withColumnRenamed(\"index_hr/wk\",\"hr/wk\").withColumnRenamed(\"index_capital_gain\",\"capital_gain\").withColumnRenamed(\"index_capital_loss\",\"capital_loss\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":5},{"cell_type":"code","source":["from pyspark.sql.functions import udf\nfrom pyspark.sql.types import *\n\n# Clearly identifying the job categories\ndef employementtype(job):\n  if(job=='Never-worked'or job=='Without-pay'):\n    return \"Unemployed\"\n  if(job=='State-gov' or job=='Local-gov'):\n    return \"Govt\"\n  if(job=='Self-emp-inc' or job=='Self-emp-not-inc'):\n    return \"self_emp\"\n  else:\n    return(job)\n  \n# For Distinguishing mrital status into 3 categories    \ndef maritalstat(mar):\n  #mar= as.character(mar)\n  \n  if mar in ['Separated','Widowed','Divorced']:\n    return \"Not-Married\"\n  elif mar== 'Never-married':\n    return \"Never-married\"\n  else: \n    return \"Married\"\n\n  \n# For Distinguishing countries into continents  \nAsia=['China','Hong','India','Iran','Cambodia','Japan', 'Laos',\n        ' Philippines' ,' Vietnam' ,' Taiwan', ' Thailand']\nNorth_America = ['Canada','United-States','Puerto-Rico' ]\n\nEurope = ['England' ,'France', 'Germany' ,'Greece','Holand-Netherlands','Hungary',\n            'Ireland','Italy','Poland','Portugal','Scotland','Yugoslavia']\n\nLatin_and_SouthAmerica = ['Columbia','Cuba','Dominican-Republic','Ecuador',\n                             'El-Salvador','Guatemala',' Haiti',' Honduras',\n                             'Mexico','Nicaragua','Outlying-US(Guam-USVI-etc)','Peru',\n                             'Jamaica','Trinadad&Tobago']\nOther= ['South']\n\ndef regionlist(countries):\n  if countries in Asia:\n    return \"Asia\"\n  if countries in North_America:\n    return \"North America\"\n  if countries in Europe:\n    return \"Europe\"\n  if countries in Latin_and_SouthAmerica:\n    return \"Latin & South America\"\n  else:\n    return \"Others\"  \n\n\n#CALLING USER DEFINED FUNCTIONS\netype_udf = udf(employementtype,StringType())\nstep6 = step5.withColumn(\"employer_type\", etype_udf(\"employer_type\"))\n\n# udf(user defined function) the function and its type and then use withcolumn to apply the transformation\nmarital_udf = udf(maritalstat,StringType())\nstep6 = step6.withColumn(\"marital\", marital_udf(\"marital\"))\n\nregion_udf = udf(regionlist,StringType())\nstep6 = step6.withColumn(\"region\",region_udf(\"region\"))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":6},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["#CHECK FOR DISTINCT VALUES in every feature/variable/column\nfor col,dtype in step6.dtypes:\n    print(col)\n    step6.select(col).distinct().show()\n    print(\"----------------------------------------\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">employer_type\n+-------------+\nemployer_type|\n+-------------+\n         Govt|\n     self_emp|\n      Private|\n  Federal-gov|\n   Unemployed|\n+-------------+\n\n----------------------------------------\neducation\n+------------+\n   education|\n+------------+\n        10th|\n     Masters|\n     5th-6th|\n  Assoc-acdm|\n   Assoc-voc|\n     7th-8th|\n         9th|\n     HS-grad|\n   Bachelors|\n        11th|\n     1st-4th|\n   Preschool|\n        12th|\n   Doctorate|\nSome-college|\n Prof-school|\n+------------+\n\n----------------------------------------\nmarital\n+-------------+\n      marital|\n+-------------+\n      Married|\nNever-married|\n  Not-Married|\n+-------------+\n\n----------------------------------------\noccupation\n+-----------------+\n       occupation|\n+-----------------+\n            Sales|\n  Exec-managerial|\n   Prof-specialty|\nHandlers-cleaners|\n  Farming-fishing|\n     Craft-repair|\n Transport-moving|\n  Priv-house-serv|\n  Protective-serv|\n    Other-service|\n     Tech-support|\nMachine-op-inspct|\n     Armed-Forces|\n     Adm-clerical|\n+-----------------+\n\n----------------------------------------\nrelationship\n+--------------+\n  relationship|\n+--------------+\n     Own-child|\n Not-in-family|\n     Unmarried|\n          Wife|\nOther-relative|\n       Husband|\n+--------------+\n\n----------------------------------------\nrace\n+------------------+\n              race|\n+------------------+\n             Other|\nAmer-Indian-Eskimo|\n             White|\nAsian-Pac-Islander|\n             Black|\n+------------------+\n\n----------------------------------------\ngender\n+------+\ngender|\n+------+\nFemale|\n  Male|\n+------+\n\n----------------------------------------\nregion\n+--------------------+\n              region|\n+--------------------+\n              Europe|\nLatin &amp; South Ame...|\n       North America|\n              Others|\n                Asia|\n+--------------------+\n\n----------------------------------------\nincome\n+------+\nincome|\n+------+\n &lt;=50K|\n  &gt;50K|\n+------+\n\n----------------------------------------\nage\n+---+\nage|\n+---+\n0.0|\n1.0|\n3.0|\n2.0|\n+---+\n\n----------------------------------------\nhr/wk\n+-----+\nhr/wk|\n+-----+\n  0.0|\n  1.0|\n  2.0|\n+-----+\n\n----------------------------------------\ncapital_gain\n+------------+\ncapital_gain|\n+------------+\n         0.0|\n         1.0|\n         4.0|\n         3.0|\n         2.0|\n         9.0|\n+------------+\n\n----------------------------------------\ncapital_loss\n+------------+\ncapital_loss|\n+------------+\n         8.0|\n         0.0|\n         7.0|\n         1.0|\n         4.0|\n         3.0|\n         2.0|\n         6.0|\n         5.0|\n         9.0|\n+------------+\n\n----------------------------------------\n</div>"]}}],"execution_count":8},{"cell_type":"code","source":["from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\nfrom pyspark.ml import Pipeline\n\n#feature_column = [col for col,dtype  in modeldata.dtypes if dtype =='string']\n\n#STRING INDEXER FOR ALL THE COLUMNS WITH DATATYPES== STRING\nString_index = [StringIndexer(inputCol=col, outputCol='index_'+col) for col,dtype  in step6.dtypes if dtype =='string' if col!='income']\nString_index += [StringIndexer(inputCol='income', outputCol='label')]\n\n\n#ONEHOT INDEXER FOR ALL THE COLUMNS NUMERICAL TYPE\nOnehot_index = [OneHotEncoder(dropLast=False, inputCol='index_'+col, outputCol='encoded_'+col) for col,dtype  in step6.dtypes if col not in ['age', 'hr/wk','capital_gain','capital_loss','income' ] ]\nOnehot_index += [OneHotEncoder(inputCol='age', outputCol='encoded_age')]\nOnehot_index += [OneHotEncoder(inputCol='hr/wk', outputCol='encoded_hr/wk')]\nOnehot_index += [OneHotEncoder(inputCol='capital_gain', outputCol='encoded_capital_gain')]\nOnehot_index += [OneHotEncoder(inputCol='capital_loss', outputCol='encoded_capital_loss')]\n\n\n#GENERATING ONE FEATURE VECTOR WHICH WILL GO INTO MACHINE LEARNING MODEL\nvectorassembler_stage = VectorAssembler(inputCols=['encoded_' + col for col in step6.columns if col!='income'], outputCol='features')\n\n\n#PRINT ALL THE JOBS\nprint(String_index)\nprint(Onehot_index)\nprint(vectorassembler_stage)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">[StringIndexer_a22b7d49f3d2, StringIndexer_f2773918c272, StringIndexer_0404aa3b5559, StringIndexer_2066bb819a9e, StringIndexer_a5550fc5e278, StringIndexer_eb1f9a2a70e0, StringIndexer_fc160bfdd89b, StringIndexer_3a42d3025194, StringIndexer_6c765fa3c89d]\n[OneHotEncoder_b53ea4f3cc7c, OneHotEncoder_3be82cb7d518, OneHotEncoder_3b0a68973136, OneHotEncoder_f8e5fc279d47, OneHotEncoder_ae7d93d1846a, OneHotEncoder_09e22c9674a5, OneHotEncoder_71e78229f2d1, OneHotEncoder_1cbc30d21d1d, OneHotEncoder_7f59f63a5a56, OneHotEncoder_111019691761, OneHotEncoder_fe834d93033d, OneHotEncoder_640b89833f6c]\nVectorAssembler_b1372761dc71\n</div>"]}}],"execution_count":9},{"cell_type":"code","source":["#PIPELINE CALLED ALL STAGE ==>> STRING INDEXING + ONE HOT ENCODING + VECTOR ASSEMBLER\nall_stages = String_index + Onehot_index + [vectorassembler_stage]\npipelined_fit = Pipeline(stages=all_stages).fit(step6)\n\n# SELECTING ONLY THE ENCODED COLUMNS TO SEE THE TRANSFORMATION\nfinal_columns = ['encoded_'+col for col,dtype  in step6.dtypes if col!='income'  ] + ['features', 'label']\nstep7 = pipelined_fit.transform(step6).select(final_columns)\ndisplay(step7.limit(10))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>encoded_employer_type</th><th>encoded_education</th><th>encoded_marital</th><th>encoded_occupation</th><th>encoded_relationship</th><th>encoded_race</th><th>encoded_gender</th><th>encoded_region</th><th>encoded_age</th><th>encoded_hr/wk</th><th>encoded_capital_gain</th><th>encoded_capital_loss</th><th>features</th><th>label</th></tr></thead><tbody><tr><td>List(0, 5, List(0), List(1.0))</td><td>List(0, 16, List(5), List(1.0))</td><td>List(0, 3, List(1), List(1.0))</td><td>List(0, 14, List(6), List(1.0))</td><td>List(0, 6, List(2), List(1.0))</td><td>List(0, 5, List(1), List(1.0))</td><td>List(0, 2, List(0), List(1.0))</td><td>List(0, 5, List(0), List(1.0))</td><td>List(0, 3, List(0), List(1.0))</td><td>List(0, 2, List(1), List(1.0))</td><td>List(0, 9, List(0), List(1.0))</td><td>List(0, 9, List(0), List(1.0))</td><td>List(0, 79, List(0, 10, 22, 30, 40, 45, 49, 51, 56, 60, 61, 70), List(1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0))</td><td>0.0</td></tr><tr><td>List(0, 5, List(0), List(1.0))</td><td>List(0, 16, List(0), List(1.0))</td><td>List(0, 3, List(0), List(1.0))</td><td>List(0, 14, List(9), List(1.0))</td><td>List(0, 6, List(0), List(1.0))</td><td>List(0, 5, List(0), List(1.0))</td><td>List(0, 2, List(0), List(1.0))</td><td>List(0, 5, List(0), List(1.0))</td><td>List(0, 3, List(1), List(1.0))</td><td>List(0, 2, List(), List())</td><td>List(0, 9, List(0), List(1.0))</td><td>List(0, 9, List(0), List(1.0))</td><td>List(0, 79, List(0, 5, 21, 33, 38, 44, 49, 51, 57, 61, 70), List(1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0))</td><td>0.0</td></tr><tr><td>List(0, 5, List(2), List(1.0))</td><td>List(0, 16, List(6), List(1.0))</td><td>List(0, 3, List(0), List(1.0))</td><td>List(0, 14, List(11), List(1.0))</td><td>List(0, 6, List(0), List(1.0))</td><td>List(0, 5, List(0), List(1.0))</td><td>List(0, 2, List(0), List(1.0))</td><td>List(0, 5, List(0), List(1.0))</td><td>List(0, 3, List(0), List(1.0))</td><td>List(0, 2, List(1), List(1.0))</td><td>List(0, 9, List(0), List(1.0))</td><td>List(0, 9, List(0), List(1.0))</td><td>List(0, 79, List(2, 11, 21, 35, 38, 44, 49, 51, 56, 60, 61, 70), List(1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0))</td><td>1.0</td></tr><tr><td>List(0, 5, List(0), List(1.0))</td><td>List(0, 16, List(1), List(1.0))</td><td>List(0, 3, List(0), List(1.0))</td><td>List(0, 14, List(6), List(1.0))</td><td>List(0, 6, List(0), List(1.0))</td><td>List(0, 5, List(1), List(1.0))</td><td>List(0, 2, List(0), List(1.0))</td><td>List(0, 5, List(0), List(1.0))</td><td>List(0, 3, List(1), List(1.0))</td><td>List(0, 2, List(1), List(1.0))</td><td>List(0, 9, List(0), List(1.0))</td><td>List(0, 9, List(0), List(1.0))</td><td>List(0, 79, List(0, 6, 21, 30, 38, 45, 49, 51, 57, 60, 61, 70), List(1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0))</td><td>1.0</td></tr><tr><td>List(0, 5, List(0), List(1.0))</td><td>List(0, 16, List(7), List(1.0))</td><td>List(0, 3, List(1), List(1.0))</td><td>List(0, 14, List(5), List(1.0))</td><td>List(0, 6, List(1), List(1.0))</td><td>List(0, 5, List(0), List(1.0))</td><td>List(0, 2, List(0), List(1.0))</td><td>List(0, 5, List(0), List(1.0))</td><td>List(0, 3, List(1), List(1.0))</td><td>List(0, 2, List(1), List(1.0))</td><td>List(0, 9, List(0), List(1.0))</td><td>List(0, 9, List(0), List(1.0))</td><td>List(0, 79, List(0, 12, 22, 29, 39, 44, 49, 51, 57, 60, 61, 70), List(1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0))</td><td>0.0</td></tr><tr><td>List(0, 5, List(1), List(1.0))</td><td>List(0, 16, List(9), List(1.0))</td><td>List(0, 3, List(0), List(1.0))</td><td>List(0, 14, List(1), List(1.0))</td><td>List(0, 6, List(0), List(1.0))</td><td>List(0, 5, List(0), List(1.0))</td><td>List(0, 2, List(0), List(1.0))</td><td>List(0, 5, List(0), List(1.0))</td><td>List(0, 3, List(), List())</td><td>List(0, 2, List(1), List(1.0))</td><td>List(0, 9, List(0), List(1.0))</td><td>List(0, 9, List(0), List(1.0))</td><td>List(0, 79, List(1, 14, 21, 25, 38, 44, 49, 51, 60, 61, 70), List(1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0))</td><td>1.0</td></tr><tr><td>List(0, 5, List(0), List(1.0))</td><td>List(0, 16, List(1), List(1.0))</td><td>List(0, 3, List(1), List(1.0))</td><td>List(0, 14, List(5), List(1.0))</td><td>List(0, 6, List(3), List(1.0))</td><td>List(0, 5, List(0), List(1.0))</td><td>List(0, 2, List(1), List(1.0))</td><td>List(0, 5, List(0), List(1.0))</td><td>List(0, 3, List(0), List(1.0))</td><td>List(0, 2, List(1), List(1.0))</td><td>List(0, 9, List(0), List(1.0))</td><td>List(0, 9, List(0), List(1.0))</td><td>List(0, 79, List(0, 6, 22, 29, 41, 44, 50, 51, 56, 60, 61, 70), List(1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0))</td><td>0.0</td></tr><tr><td>List(0, 5, List(0), List(1.0))</td><td>List(0, 16, List(8), List(1.0))</td><td>List(0, 3, List(0), List(1.0))</td><td>List(0, 14, List(0), List(1.0))</td><td>List(0, 6, List(0), List(1.0))</td><td>List(0, 5, List(0), List(1.0))</td><td>List(0, 2, List(0), List(1.0))</td><td>List(0, 5, List(0), List(1.0))</td><td>List(0, 3, List(2), List(1.0))</td><td>List(0, 2, List(0), List(1.0))</td><td>List(0, 9, List(0), List(1.0))</td><td>List(0, 9, List(0), List(1.0))</td><td>List(0, 79, List(0, 13, 21, 24, 38, 44, 49, 51, 58, 59, 61, 70), List(1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0))</td><td>0.0</td></tr><tr><td>List(0, 5, List(0), List(1.0))</td><td>List(0, 16, List(0), List(1.0))</td><td>List(0, 3, List(0), List(1.0))</td><td>List(0, 14, List(6), List(1.0))</td><td>List(0, 6, List(0), List(1.0))</td><td>List(0, 5, List(0), List(1.0))</td><td>List(0, 2, List(0), List(1.0))</td><td>List(0, 5, List(0), List(1.0))</td><td>List(0, 3, List(), List())</td><td>List(0, 2, List(1), List(1.0))</td><td>List(0, 9, List(0), List(1.0))</td><td>List(0, 9, List(0), List(1.0))</td><td>List(0, 79, List(0, 5, 21, 30, 38, 44, 49, 51, 60, 61, 70), List(1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0))</td><td>1.0</td></tr><tr><td>List(0, 5, List(3), List(1.0))</td><td>List(0, 16, List(2), List(1.0))</td><td>List(0, 3, List(0), List(1.0))</td><td>List(0, 14, List(3), List(1.0))</td><td>List(0, 6, List(0), List(1.0))</td><td>List(0, 5, List(0), List(1.0))</td><td>List(0, 2, List(0), List(1.0))</td><td>List(0, 5, List(0), List(1.0))</td><td>List(0, 3, List(1), List(1.0))</td><td>List(0, 2, List(1), List(1.0))</td><td>List(0, 9, List(0), List(1.0))</td><td>List(0, 9, List(0), List(1.0))</td><td>List(0, 79, List(3, 7, 21, 27, 38, 44, 49, 51, 57, 60, 61, 70), List(1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0))</td><td>0.0</td></tr></tbody></table></div>"]}}],"execution_count":10},{"cell_type":"markdown","source":["# MACHINE LEARNING Models"],"metadata":{}},{"cell_type":"code","source":["#SELECTING COLUMNS FOR MACHINE LEARNING MODEL\nmldata = step7.select(\"features\",\"label\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":12},{"cell_type":"markdown","source":["#1: Logistic Regression"],"metadata":{}},{"cell_type":"code","source":["(trainDF, testDF) = mldata.randomSplit([0.8, 0.2], seed=1231)\ntrainDF.cache()\ntestDF.cache()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[16]: DataFrame[features: vector, label: double]</div>"]}}],"execution_count":14},{"cell_type":"code","source":["from pyspark.ml.classification import LogisticRegression\n\n# Load training data\n\n\nlr = LogisticRegression()\n\n# Fit the model\nlrModel = lr.fit(trainDF)\n\n# Print the coefficients and intercept for logistic regression\nprint(\"Coefficients: \" + str(lrModel.coefficients))\nprint(\"Intercept: \" + str(lrModel.intercept))\nlrModel.summary.accuracy"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Coefficients: [0.786306134702478,0.5536625875241842,0.6094202585570349,1.2007010221944803,-0.52741408154112,0.03794175323260771,0.4062885644429996,1.1266285088671333,1.4434934821212024,0.4446186426812252,-0.6711358868919073,0.5733166630492471,-0.6650406145024941,-0.9716258901631141,1.9785612400779131,-1.1304810218293004,-0.14726173705590412,1.9309636273461876,-1.1375344171382036,-1.0874732611509743,-2.3591255202186465,1.1790566376416283,-0.10662998712512779,0.22405112653370024,0.2969213049434663,0.8110573321188834,1.0939174966735685,0.34612029068213374,0.5731466430964612,-0.5778892407224351,-0.021084321548565883,0.17769719004912624,-0.39718071682471606,-0.6210714785582705,0.9129775769169968,0.814442490487104,-0.9251725387108303,0.0429181325518015,1.0734740566388,0.20932501872306825,-0.6087418565936467,-0.03432353975382116,2.0777149383407294,-0.2530416563595561,1.3133682823733925,1.0848888310881546,1.599036320465884,0.6122206792611494,1.2099747888402486,1.0063602434933978,0.3911940319189905,2.2758136904234503,1.6053079055655584,2.481275066402028,1.7169116761301695,1.7473139592996512,-0.975174548928968,0.0606099642309338,0.4486005512315896,-1.511983123102963,-0.45762051021013483,-10.805044329316067,-4.55899142649114,9.362937223215114,-19.524804244358407,-21.035214578002318,0.0,0.0,0.0,0.0,3.0438199539795296,2.6739400846472514,-11.416549418794306,2.388665772576111,4.610025498912995,4.912979875276808,7.7323834514450285,-3.599874302357182,-8.16666342732313]\nIntercept: -0.8050893414640454\nOut[17]: 0.845414774615129</div>"]}}],"execution_count":15},{"cell_type":"code","source":["#for test df\nresult = lrModel.transform(testDF)\nresult.select(\"prediction\",\"label\",\"features\").show(10)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----------+-----+--------------------+\nprediction|label|            features|\n+----------+-----+--------------------+\n       0.0|  0.0|(79,[0,5,21,24,38...|\n       0.0|  0.0|(79,[0,5,21,24,38...|\n       0.0|  0.0|(79,[0,5,21,24,38...|\n       0.0|  0.0|(79,[0,5,21,24,38...|\n       0.0|  0.0|(79,[0,5,21,24,38...|\n       0.0|  0.0|(79,[0,5,21,24,38...|\n       0.0|  0.0|(79,[0,5,21,24,38...|\n       0.0|  0.0|(79,[0,5,21,24,38...|\n       0.0|  0.0|(79,[0,5,21,24,38...|\n       0.0|  0.0|(79,[0,5,21,24,38...|\n+----------+-----+--------------------+\nonly showing top 10 rows\n\n</div>"]}}],"execution_count":16},{"cell_type":"code","source":["from pyspark.ml.evaluation import BinaryClassificationEvaluator\n\nevaluator = BinaryClassificationEvaluator()\nprint(\"AUC: %(result)s\" % {\"result\": evaluator.evaluate(result)})\ndisplay(lrModel, trainDF, \"ROC\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>False Positive Rate</th><th>True Positive Rate</th><th>Threshold</th></tr></thead><tbody><tr><td>0.0</td><td>0.0</td><td>0.9997586412226628</td></tr><tr><td>0.0</td><td>0.047619047619047616</td><td>0.9997586412226628</td></tr><tr><td>0.0</td><td>0.09523809523809523</td><td>0.9964595733598345</td></tr><tr><td>0.0</td><td>0.14285714285714285</td><td>0.8410533217230212</td></tr><tr><td>0.0</td><td>0.19047619047619047</td><td>0.8343621720435789</td></tr><tr><td>0.012345679012345678</td><td>0.19047619047619047</td><td>0.812373482632714</td></tr><tr><td>0.012345679012345678</td><td>0.23809523809523808</td><td>0.7940022908330541</td></tr><tr><td>0.012345679012345678</td><td>0.2857142857142857</td><td>0.7868378812055389</td></tr><tr><td>0.012345679012345678</td><td>0.3333333333333333</td><td>0.7533533727829665</td></tr><tr><td>0.012345679012345678</td><td>0.42857142857142855</td><td>0.7439042883617669</td></tr><tr><td>0.012345679012345678</td><td>0.47619047619047616</td><td>0.727861070073666</td></tr><tr><td>0.024691358024691357</td><td>0.47619047619047616</td><td>0.6346516784815749</td></tr><tr><td>0.024691358024691357</td><td>0.5238095238095238</td><td>0.6063164778880358</td></tr><tr><td>0.037037037037037035</td><td>0.5238095238095238</td><td>0.581197691009374</td></tr><tr><td>0.04938271604938271</td><td>0.5714285714285714</td><td>0.5318952002616767</td></tr><tr><td>0.06172839506172839</td><td>0.5714285714285714</td><td>0.4900851071367073</td></tr><tr><td>0.06172839506172839</td><td>0.6190476190476191</td><td>0.45300270130936726</td></tr><tr><td>0.07407407407407407</td><td>0.6190476190476191</td><td>0.450887378245991</td></tr><tr><td>0.08641975308641975</td><td>0.6190476190476191</td><td>0.4445544102693786</td></tr><tr><td>0.08641975308641975</td><td>0.6666666666666666</td><td>0.44084219352170245</td></tr><tr><td>0.08641975308641975</td><td>0.7142857142857143</td><td>0.42865545993149595</td></tr><tr><td>0.09876543209876543</td><td>0.7142857142857143</td><td>0.41827317079940224</td></tr><tr><td>0.1111111111111111</td><td>0.7142857142857143</td><td>0.40585809500928566</td></tr><tr><td>0.12345679012345678</td><td>0.7142857142857143</td><td>0.3822648454185685</td></tr><tr><td>0.13580246913580246</td><td>0.7142857142857143</td><td>0.3628616192705575</td></tr><tr><td>0.14814814814814814</td><td>0.7142857142857143</td><td>0.3301951703243776</td></tr><tr><td>0.14814814814814814</td><td>0.7619047619047619</td><td>0.3278650999888689</td></tr><tr><td>0.16049382716049382</td><td>0.7619047619047619</td><td>0.32278288824095674</td></tr><tr><td>0.1728395061728395</td><td>0.7619047619047619</td><td>0.3219205991109156</td></tr><tr><td>0.1728395061728395</td><td>0.8095238095238095</td><td>0.29114311634037227</td></tr><tr><td>0.1728395061728395</td><td>0.8571428571428571</td><td>0.2837180725810495</td></tr><tr><td>0.18518518518518517</td><td>0.8571428571428571</td><td>0.28339684503237356</td></tr><tr><td>0.19753086419753085</td><td>0.8571428571428571</td><td>0.2701065291953623</td></tr><tr><td>0.20987654320987653</td><td>0.8571428571428571</td><td>0.26009716720837545</td></tr><tr><td>0.2222222222222222</td><td>0.8571428571428571</td><td>0.24739480737067976</td></tr><tr><td>0.2345679012345679</td><td>0.8571428571428571</td><td>0.2472550108057697</td></tr><tr><td>0.24691358024691357</td><td>0.8571428571428571</td><td>0.23923923292289248</td></tr><tr><td>0.25925925925925924</td><td>0.8571428571428571</td><td>0.23415106385967208</td></tr><tr><td>0.25925925925925924</td><td>0.9047619047619048</td><td>0.22453277747141112</td></tr><tr><td>0.2716049382716049</td><td>0.9047619047619048</td><td>0.21213769171858102</td></tr><tr><td>0.2839506172839506</td><td>0.9047619047619048</td><td>0.20218433398150668</td></tr><tr><td>0.2962962962962963</td><td>0.9047619047619048</td><td>0.1956337517364458</td></tr><tr><td>0.30864197530864196</td><td>0.9047619047619048</td><td>0.19532390848125342</td></tr><tr><td>0.32098765432098764</td><td>0.9047619047619048</td><td>0.1763761446851283</td></tr><tr><td>0.345679012345679</td><td>0.9047619047619048</td><td>0.17189641925823632</td></tr><tr><td>0.345679012345679</td><td>0.9523809523809523</td><td>0.16636545788785098</td></tr><tr><td>0.35802469135802467</td><td>0.9523809523809523</td><td>0.1561578653644085</td></tr><tr><td>0.37037037037037035</td><td>0.9523809523809523</td><td>0.15601478726105975</td></tr><tr><td>0.38271604938271603</td><td>0.9523809523809523</td><td>0.14358896533463741</td></tr><tr><td>0.3950617283950617</td><td>0.9523809523809523</td><td>0.13366989778738658</td></tr><tr><td>0.4074074074074074</td><td>0.9523809523809523</td><td>0.12713176350531097</td></tr><tr><td>0.4074074074074074</td><td>1.0</td><td>0.12248640306880823</td></tr><tr><td>0.41975308641975306</td><td>1.0</td><td>0.12173325575856303</td></tr><tr><td>0.43209876543209874</td><td>1.0</td><td>0.11750397168998739</td></tr><tr><td>0.4444444444444444</td><td>1.0</td><td>0.1161026038095926</td></tr><tr><td>0.4567901234567901</td><td>1.0</td><td>0.09013116879952578</td></tr><tr><td>0.4691358024691358</td><td>1.0</td><td>0.0839606778531385</td></tr><tr><td>0.48148148148148145</td><td>1.0</td><td>0.0798784382317683</td></tr><tr><td>0.49382716049382713</td><td>1.0</td><td>0.07064131751123788</td></tr><tr><td>0.5061728395061729</td><td>1.0</td><td>0.06638165375413246</td></tr><tr><td>0.5185185185185185</td><td>1.0</td><td>0.06454793220497262</td></tr><tr><td>0.5308641975308642</td><td>1.0</td><td>0.06315902203306667</td></tr><tr><td>0.5432098765432098</td><td>1.0</td><td>0.05927143028887436</td></tr><tr><td>0.5555555555555556</td><td>1.0</td><td>0.05865863708397154</td></tr><tr><td>0.5679012345679012</td><td>1.0</td><td>0.057026536656005815</td></tr><tr><td>0.5802469135802469</td><td>1.0</td><td>0.05331643494214292</td></tr><tr><td>0.5925925925925926</td><td>1.0</td><td>0.05066031247919894</td></tr><tr><td>0.6049382716049383</td><td>1.0</td><td>0.047824407052174236</td></tr><tr><td>0.6172839506172839</td><td>1.0</td><td>0.046435574755949165</td></tr><tr><td>0.6296296296296297</td><td>1.0</td><td>0.04492114592741861</td></tr><tr><td>0.6419753086419753</td><td>1.0</td><td>0.03731340625648253</td></tr><tr><td>0.654320987654321</td><td>1.0</td><td>0.03541385036979833</td></tr><tr><td>0.6666666666666666</td><td>1.0</td><td>0.033773069043844174</td></tr><tr><td>0.6790123456790124</td><td>1.0</td><td>0.03295175274983356</td></tr><tr><td>0.691358024691358</td><td>1.0</td><td>0.03083620595071603</td></tr><tr><td>0.7037037037037037</td><td>1.0</td><td>0.030091496166602665</td></tr><tr><td>0.7160493827160493</td><td>1.0</td><td>0.028093940914267142</td></tr><tr><td>0.7283950617283951</td><td>1.0</td><td>0.02696963213794338</td></tr><tr><td>0.7407407407407407</td><td>1.0</td><td>0.024524686052676537</td></tr><tr><td>0.7530864197530864</td><td>1.0</td><td>0.02220206791730697</td></tr><tr><td>0.7777777777777778</td><td>1.0</td><td>0.019630601275939234</td></tr><tr><td>0.7901234567901234</td><td>1.0</td><td>0.017157308538523246</td></tr><tr><td>0.8024691358024691</td><td>1.0</td><td>0.015563736126663662</td></tr><tr><td>0.8148148148148148</td><td>1.0</td><td>0.015138488954560877</td></tr><tr><td>0.8271604938271605</td><td>1.0</td><td>0.013391341679174398</td></tr><tr><td>0.8395061728395061</td><td>1.0</td><td>0.012971681019351691</td></tr><tr><td>0.8518518518518519</td><td>1.0</td><td>0.008939723754849643</td></tr><tr><td>0.8641975308641975</td><td>1.0</td><td>0.006906490046980622</td></tr><tr><td>0.8765432098765432</td><td>1.0</td><td>0.006277568172949797</td></tr><tr><td>0.8888888888888888</td><td>1.0</td><td>0.005910915920099402</td></tr><tr><td>0.9012345679012346</td><td>1.0</td><td>0.004889445994731853</td></tr><tr><td>0.9135802469135802</td><td>1.0</td><td>0.00312999015506081</td></tr><tr><td>0.9259259259259259</td><td>1.0</td><td>0.002795019533166732</td></tr><tr><td>0.9382716049382716</td><td>1.0</td><td>0.0020770266224326025</td></tr><tr><td>0.9506172839506173</td><td>1.0</td><td>9.25997256811886E-4</td></tr><tr><td>0.9629629629629629</td><td>1.0</td><td>8.520557012234667E-4</td></tr><tr><td>0.9753086419753086</td><td>1.0</td><td>8.163553170668326E-4</td></tr><tr><td>0.9876543209876543</td><td>1.0</td><td>5.299972615159394E-4</td></tr><tr><td>1.0</td><td>1.0</td><td>1.8971254885392504E-4</td></tr><tr><td>1.0</td><td>1.0</td><td>1.8971254885392504E-4</td></tr></tbody></table></div>"]}}],"execution_count":17},{"cell_type":"code","source":["display(lrModel, trainDF)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>fitted values</th><th>residuals</th></tr></thead><tbody><tr><td>-2.0298666724904644</td><td>-0.1161026038095926</td></tr><tr><td>-1.5722461622803294</td><td>-0.17189641925823632</td></tr><tr><td>-0.9940821593305625</td><td>-0.2701065291953623</td></tr><tr><td>5.639961330495028</td><td>0.003540426640165517</td></tr><tr><td>-0.47994613215514365</td><td>-0.3822648454185685</td></tr><tr><td>-0.717856821177567</td><td>0.6721349000111311</td></tr><tr><td>-0.3298662341769112</td><td>-0.41827317079940224</td></tr><tr><td>0.12775427603322276</td><td>-0.5318952002616767</td></tr><tr><td>0.12775427603322276</td><td>0.4681047997383233</td></tr><tr><td>-1.3726977500535278</td><td>-0.20218433398150668</td></tr><tr><td>-1.1133062742249027</td><td>-0.2472550108057697</td></tr><tr><td>-1.688184181098745</td><td>-0.15601478726105975</td></tr><tr><td>-1.413810400516933</td><td>-0.1956337517364458</td></tr><tr><td>-7.542108580622804</td><td>-5.299972615159394E-4</td></tr><tr><td>-4.708270667335328</td><td>-0.008939723754849643</td></tr><tr><td>-5.315774836981699</td><td>-0.004889445994731853</td></tr><tr><td>-2.805521426697256</td><td>-0.057026536656005815</td></tr><tr><td>-3.056885266831112</td><td>-0.04492114592741861</td></tr><tr><td>-1.7857956309877367</td><td>-0.14358896533463741</td></tr><tr><td>-3.910839799835319</td><td>-0.019630601275939234</td></tr><tr><td>-3.910839799835319</td><td>-0.019630601275939234</td></tr><tr><td>-3.3792039341899627</td><td>-0.03295175274983356</td></tr><tr><td>-5.125026027021187</td><td>-0.005910915920099402</td></tr><tr><td>-2.67362182463612</td><td>-0.06454793220497262</td></tr><tr><td>-4.048024841625147</td><td>-0.017157308538523246</td></tr><tr><td>-0.18854577538084694</td><td>0.5469972986906327</td></tr><tr><td>-0.9276740129169425</td><td>-0.28339684503237356</td></tr><tr><td>-0.7449594630145107</td><td>-0.3219205991109156</td></tr><tr><td>-0.2873389528043757</td><td>0.571344540068504</td></tr><tr><td>-1.0454635893065427</td><td>-0.26009716720837545</td></tr><tr><td>-3.3537350137524258</td><td>-0.033773069043844174</td></tr><tr><td>-2.7755710108026586</td><td>-0.05865863708397154</td></tr><tr><td>-3.683244649436653</td><td>-0.024524686052676537</td></tr><tr><td>-4.968363272700687</td><td>-0.006906490046980622</td></tr><tr><td>-3.4729591286467656</td><td>-0.030091496166602665</td></tr><tr><td>-2.443999836744707</td><td>-0.0798784382317683</td></tr><tr><td>0.5522251065140991</td><td>-0.6346516784815749</td></tr><tr><td>1.0663611336895151</td><td>0.2560957116382331</td></tr><tr><td>1.0663611336895151</td><td>0.2560957116382331</td></tr><tr><td>1.3492212982442013</td><td>0.20599770916694593</td></tr><tr><td>-2.576879552363009</td><td>-0.07064131751123788</td></tr><tr><td>-1.5410950392031075</td><td>-0.1763761446851283</td></tr><tr><td>-1.4157805760126947</td><td>-0.19532390848125342</td></tr><tr><td>-3.7851176013066095</td><td>-0.02220206791730697</td></tr><tr><td>-2.6436470124354017</td><td>-0.06638165375413246</td></tr><tr><td>-1.6116081853854416</td><td>0.833634542112149</td></tr><tr><td>-0.03966477099750898</td><td>-0.4900851071367073</td></tr><tr><td>-0.2226982007348679</td><td>-0.4445544102693786</td></tr><tr><td>-2.696857848512038</td><td>-0.06315902203306667</td></tr><tr><td>-5.877117250894948</td><td>-0.002795019533166732</td></tr><tr><td>-5.763590520963369</td><td>-0.00312999015506081</td></tr><tr><td>-4.331930132791367</td><td>-0.012971681019351691</td></tr><tr><td>-2.3897107234160755</td><td>-0.0839606778531385</td></tr><tr><td>-1.969092421830581</td><td>0.8775135969311918</td></tr><tr><td>-3.4477441142329406</td><td>-0.03083620595071603</td></tr><tr><td>-1.2394440168555296</td><td>0.7754672225285889</td></tr><tr><td>-3.0221411270763663</td><td>-0.046435574755949165</td></tr><tr><td>-2.8767202612160876</td><td>-0.05331643494214292</td></tr><tr><td>-4.2996651099081635</td><td>-0.013391341679174398</td></tr><tr><td>-4.175260595186064</td><td>-0.015138488954560877</td></tr><tr><td>-3.2503752318636385</td><td>-0.03731340625648253</td></tr><tr><td>-0.3811146092980664</td><td>-0.40585809500928566</td></tr><tr><td>-1.976118133624722</td><td>-0.12173325575856303</td></tr><tr><td>-1.687097979800458</td><td>-0.1561578653644085</td></tr><tr><td>8.328984640939735</td><td>2.4135877733721944E-4</td></tr><tr><td>-2.312034407169387</td><td>-0.09013116879952578</td></tr><tr><td>0.3276919665591611</td><td>-0.581197691009374</td></tr><tr><td>1.1165777510659072</td><td>0.24664662721703345</td></tr><tr><td>0.983797484489454</td><td>0.27213892992633404</td></tr><tr><td>-6.9837128594715265</td><td>-9.25997256811886E-4</td></tr><tr><td>-3.585703794862981</td><td>-0.02696963213794338</td></tr><tr><td>-0.5629653227195743</td><td>-0.3628616192705575</td></tr><tr><td>0.43185474733393836</td><td>0.3936835221119642</td></tr><tr><td>-1.1568549160533388</td><td>-0.23923923292289248</td></tr><tr><td>-2.0162821536688895</td><td>-0.11750397168998739</td></tr><tr><td>-0.9260927999118873</td><td>0.7162819274189505</td></tr><tr><td>1.6168639215870313</td><td>0.16563782795642112</td></tr><tr><td>1.4655068112414844</td><td>-0.812373482632714</td></tr><tr><td>-2.9306238644380898</td><td>-0.05066031247919894</td></tr><tr><td>-0.7073024660946704</td><td>-0.3301951703243776</td></tr><tr><td>-1.5722461622803294</td><td>-0.17189641925823632</td></tr><tr><td>-0.1970859676004576</td><td>-0.450887378245991</td></tr><tr><td>1.3059692339660334</td><td>0.21316211879446112</td></tr><tr><td>-1.868892704996464</td><td>-0.13366989778738658</td></tr><tr><td>-1.3120877858225946</td><td>-0.21213769171858102</td></tr><tr><td>-4.147125555496847</td><td>-0.015563736126663662</td></tr><tr><td>-2.991213347189306</td><td>-0.047824407052174236</td></tr><tr><td>-3.5437052254963577</td><td>-0.028093940914267142</td></tr><tr><td>-0.23774476111951492</td><td>0.5591578064782976</td></tr><tr><td>-1.1125553067854161</td><td>-0.24739480737067976</td></tr><tr><td>-6.174738729803069</td><td>-0.0020770266224326025</td></tr><tr><td>-3.304596151860974</td><td>-0.03541385036979833</td></tr><tr><td>-5.064475252146959</td><td>-0.006277568172949797</td></tr><tr><td>-1.926560556062881</td><td>-0.12713176350531097</td></tr><tr><td>1.6660862714982696</td><td>0.15894667827697884</td></tr><tr><td>-1.1850184598712434</td><td>-0.23415106385967208</td></tr><tr><td>-0.8898386945378448</td><td>0.7088568836596277</td></tr><tr><td>-7.109844171477167</td><td>-8.163553170668326E-4</td></tr><tr><td>-8.569810801616004</td><td>-1.8971254885392504E-4</td></tr><tr><td>-0.7410119937528837</td><td>-0.32278288824095674</td></tr><tr><td>-2.7645272419505043</td><td>-0.05927143028887436</td></tr><tr><td>-7.067006237342083</td><td>-8.520557012234667E-4</td></tr></tbody></table></div>"]}}],"execution_count":18},{"cell_type":"code","source":["from pyspark.ml.evaluation import BinaryClassificationEvaluator\n\n# Let's use the run-of-the-mill evaluator\nevaluator = BinaryClassificationEvaluator(labelCol='label')\n\n# We have only two choices: area under ROC and PR curves :-(\nauroc = evaluator.evaluate(result, {evaluator.metricName: \"areaUnderROC\"})\nauprc = evaluator.evaluate(result, {evaluator.metricName: \"areaUnderPR\"})\nprint(\"Area under ROC Curve: {:.4f}\".format(auroc))\nprint(\"Area under PR Curve: {:.4f}\".format(auprc))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Area under ROC Curve: 0.9060\nArea under PR Curve: 0.7665\n</div>"]}}],"execution_count":19},{"cell_type":"code","source":["from pyspark.ml.evaluation import BinaryClassificationEvaluator\nlr.setRegParam(0.08)\n\nmodel = lr.fit(trainDF)\n#training = model.transform(trainDF)\nresult = model.transform(testDF)\nprint(\"evaluations %(result)s\" % {\"result\": BinaryClassificationEvaluator().evaluate(result)})"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">evaluations 0.9035111044157303\n</div>"]}}],"execution_count":20},{"cell_type":"code","source":["from pyspark.mllib.evaluation import MulticlassMetrics\nfrom pyspark.sql.types import FloatType\n\n#important: need to cast to float type, and order by prediction, else it won't work\npreds_and_labels = result.select(['prediction','label']).withColumn('label', F.col('label').cast(FloatType())).orderBy('prediction')\n#select only prediction and label columns\npreds_and_labels = preds_and_labels.select(['prediction','label'])\n\nmetrics = MulticlassMetrics(preds_and_labels.rdd.map(tuple))\n\nprint(metrics.confusionMatrix().toArray())\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">[[6521.  316.]\n [1154. 1115.]]\n</div>"]}}],"execution_count":21},{"cell_type":"code","source":["# We are trying for all possible evaluations possible"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":22},{"cell_type":"code","source":["from pyspark.ml.classification import LogisticRegression\nlogr = LogisticRegression(featuresCol='features', labelCol='label')\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":23},{"cell_type":"code","source":["from pyspark.ml.tuning import ParamGridBuilder\nparam_grid = ParamGridBuilder().\\\n      addGrid(logr.regParam, [0, 0.1, 0.2, 0.5, 1]).\\\n      addGrid(logr.elasticNetParam, [0, 0.1, 0.2, 0.5, 1]).\\\n      addGrid(logr.maxIter, [5,10,20,50,100]).\\\n      build()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":24},{"cell_type":"code","source":["from pyspark.ml.evaluation import BinaryClassificationEvaluator\nevaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":25},{"cell_type":"code","source":["from pyspark.ml.tuning import CrossValidator\ncv = CrossValidator(estimator=logr, evaluator=evaluator, estimatorParamMaps=param_grid, numFolds=3)\ncv_model = cv.fit(trainDF)  # fitiing data to my cross validation model"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">MLlib will automatically track trials in MLflow. After your tuning fit() call has completed, view the MLflow UI to see logged runs.\n</div>"]}}],"execution_count":26},{"cell_type":"code","source":["show_columns = ['features', 'label', 'prediction', 'rawPrediction', 'probability']\npred_training_cv = cv_model.transform(trainDF)\npred_training_cv.select(show_columns).show(5, truncate=False)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+------------------------------------------------------------------------------------------+-----+----------+----------------------------------------+---------------------------------------+\nfeatures                                                                                  |label|prediction|rawPrediction                           |probability                            |\n+------------------------------------------------------------------------------------------+-----+----------+----------------------------------------+---------------------------------------+\n(79,[0,5,21,24,38,44,49,51,56,60,61,70],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])|0.0  |0.0       |[2.0298666724904644,-2.0298666724904644]|[0.8838973961904073,0.1161026038095926]|\n(79,[0,5,21,24,38,44,49,51,56,60,61,70],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])|0.0  |0.0       |[2.0298666724904644,-2.0298666724904644]|[0.8838973961904073,0.1161026038095926]|\n(79,[0,5,21,24,38,44,49,51,56,60,61,70],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])|0.0  |0.0       |[2.0298666724904644,-2.0298666724904644]|[0.8838973961904073,0.1161026038095926]|\n(79,[0,5,21,24,38,44,49,51,56,60,61,70],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])|0.0  |0.0       |[2.0298666724904644,-2.0298666724904644]|[0.8838973961904073,0.1161026038095926]|\n(79,[0,5,21,24,38,44,49,51,56,60,61,70],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])|0.0  |0.0       |[2.0298666724904644,-2.0298666724904644]|[0.8838973961904073,0.1161026038095926]|\n+------------------------------------------------------------------------------------------+-----+----------+----------------------------------------+---------------------------------------+\nonly showing top 5 rows\n\n</div>"]}}],"execution_count":27},{"cell_type":"code","source":["pred_test_cv = cv_model.transform(testDF)\npred_test_cv.select(show_columns).show(5, truncate=False)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+------------------------------------------------------------------------------------------+-----+----------+----------------------------------------+---------------------------------------+\nfeatures                                                                                  |label|prediction|rawPrediction                           |probability                            |\n+------------------------------------------------------------------------------------------+-----+----------+----------------------------------------+---------------------------------------+\n(79,[0,5,21,24,38,44,49,51,56,60,61,70],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])|0.0  |0.0       |[2.0298666724904644,-2.0298666724904644]|[0.8838973961904073,0.1161026038095926]|\n(79,[0,5,21,24,38,44,49,51,56,60,61,70],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])|0.0  |0.0       |[2.0298666724904644,-2.0298666724904644]|[0.8838973961904073,0.1161026038095926]|\n(79,[0,5,21,24,38,44,49,51,56,60,61,70],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])|0.0  |0.0       |[2.0298666724904644,-2.0298666724904644]|[0.8838973961904073,0.1161026038095926]|\n(79,[0,5,21,24,38,44,49,51,56,60,61,70],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])|0.0  |0.0       |[2.0298666724904644,-2.0298666724904644]|[0.8838973961904073,0.1161026038095926]|\n(79,[0,5,21,24,38,44,49,51,56,60,61,70],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])|0.0  |0.0       |[2.0298666724904644,-2.0298666724904644]|[0.8838973961904073,0.1161026038095926]|\n+------------------------------------------------------------------------------------------+-----+----------+----------------------------------------+---------------------------------------+\nonly showing top 5 rows\n\n</div>"]}}],"execution_count":28},{"cell_type":"code","source":["print('Intercept: ' + str(cv_model.bestModel.intercept) + \"\\n\" 'coefficients: ' + str(cv_model.bestModel.coefficients))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Intercept: -0.8050893414640454\ncoefficients: [0.786306134702478,0.5536625875241842,0.6094202585570349,1.2007010221944803,-0.52741408154112,0.03794175323260771,0.4062885644429996,1.1266285088671333,1.4434934821212024,0.4446186426812252,-0.6711358868919073,0.5733166630492471,-0.6650406145024941,-0.9716258901631141,1.9785612400779131,-1.1304810218293004,-0.14726173705590412,1.9309636273461876,-1.1375344171382036,-1.0874732611509743,-2.3591255202186465,1.1790566376416283,-0.10662998712512779,0.22405112653370024,0.2969213049434663,0.8110573321188834,1.0939174966735685,0.34612029068213374,0.5731466430964612,-0.5778892407224351,-0.021084321548565883,0.17769719004912624,-0.39718071682471606,-0.6210714785582705,0.9129775769169968,0.814442490487104,-0.9251725387108303,0.0429181325518015,1.0734740566388,0.20932501872306825,-0.6087418565936467,-0.03432353975382116,2.0777149383407294,-0.2530416563595561,1.3133682823733925,1.0848888310881546,1.599036320465884,0.6122206792611494,1.2099747888402486,1.0063602434933978,0.3911940319189905,2.2758136904234503,1.6053079055655584,2.481275066402028,1.7169116761301695,1.7473139592996512,-0.975174548928968,0.0606099642309338,0.4486005512315896,-1.511983123102963,-0.45762051021013483,-10.805044329316067,-4.55899142649114,9.362937223215114,-19.524804244358407,-21.035214578002318,0.0,0.0,0.0,0.0,3.0438199539795296,2.6739400846472514,-11.416549418794306,2.388665772576111,4.610025498912995,4.912979875276808,7.7323834514450285,-3.599874302357182,-8.16666342732313]\n</div>"]}}],"execution_count":29},{"cell_type":"code","source":["print('Logistic Regression', \"\\n\",'The best RegParam is: ', cv_model.bestModel._java_obj.getRegParam(), \"\\n\",'The best ElasticNetParam is:', cv_model.bestModel._java_obj.getElasticNetParam(), \"\\n\",'The best Iteration is:',cv_model.bestModel._java_obj.getMaxIter() , \"\\n\", 'Area under ROC is:', cv_model.bestModel.summary.areaUnderROC)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Logistic Regression \n The best RegParam is:  0.0 \n The best ElasticNetParam is: 0.0 \n The best Iteration is: 100 \n Area under ROC is: 0.9018748530240799\n</div>"]}}],"execution_count":30},{"cell_type":"code","source":["cv_model.avgMetrics"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[50]: [0.8896683662782221,\n 0.8998937195983895,\n 0.9004334619977938,\n 0.9004664877390309,\n 0.9005118127822711,\n 0.889668366278217,\n 0.8998937195983905,\n 0.9004334619977958,\n 0.9004664877390317,\n 0.9005118127822545,\n 0.8896683662782174,\n 0.8998937195983865,\n 0.9004334619977958,\n 0.9004664877390306,\n 0.9005118127822631,\n 0.8896683662782192,\n 0.8998937195983838,\n 0.9004334619977985,\n 0.9004664877390277,\n 0.900511812782258,\n 0.8896683662782183,\n 0.8998937195983867,\n 0.9004334619977941,\n 0.9004664877390358,\n 0.9005118127822707,\n 0.8933768234315995,\n 0.8971648203240595,\n 0.897614202504573,\n 0.89760454668057,\n 0.8976045466805695,\n 0.8804202245080925,\n 0.8922807520051561,\n 0.8924828005312846,\n 0.892577082726433,\n 0.8927571779318053,\n 0.8756781787718766,\n 0.8855767276454898,\n 0.8828874541957528,\n 0.8838672878717075,\n 0.8838793794601774,\n 0.8593286192959567,\n 0.8612872294797924,\n 0.8591056153790473,\n 0.8605500343469199,\n 0.8614497035616788,\n 0.8038190268070557,\n 0.7786148503665706,\n 0.7757425006851344,\n 0.7733662923002796,\n 0.7733662923002796,\n 0.89209015602976,\n 0.8949482192144185,\n 0.8955081629206852,\n 0.8954914158217552,\n 0.895491415821754,\n 0.8758315576264503,\n 0.8826604374887821,\n 0.8832491138529024,\n 0.8835890070575485,\n 0.8833868855418585,\n 0.8659119978788501,\n 0.8697065120254273,\n 0.8684789499538681,\n 0.8701622360061434,\n 0.8703633552967125,\n 0.8063172258502393,\n 0.7864405089275053,\n 0.7786148503665706,\n 0.7786148503665706,\n 0.7786148503665706,\n 0.5,\n 0.5,\n 0.5,\n 0.5,\n 0.5,\n 0.8891977161478004,\n 0.8916334086986604,\n 0.891695200419202,\n 0.8916968639807932,\n 0.8916968639807943,\n 0.8591611122309617,\n 0.8610635223953156,\n 0.8615313157820117,\n 0.8625823280143265,\n 0.8626500987636727,\n 0.7999105762272873,\n 0.8018867702854015,\n 0.8004309106029105,\n 0.8004309106029105,\n 0.8004309106029105,\n 0.5,\n 0.5,\n 0.5,\n 0.5,\n 0.5,\n 0.5,\n 0.5,\n 0.5,\n 0.5,\n 0.5,\n 0.8873408027460119,\n 0.8898560340655057,\n 0.8884224181596265,\n 0.888422418159627,\n 0.8884224181596293,\n 0.8004309106029105,\n 0.7999105762272875,\n 0.7999105762272875,\n 0.7999105762272875,\n 0.7999105762272875,\n 0.5,\n 0.5,\n 0.5,\n 0.5,\n 0.5,\n 0.5,\n 0.5,\n 0.5,\n 0.5,\n 0.5,\n 0.5,\n 0.5,\n 0.5,\n 0.5,\n 0.5]</div>"]}}],"execution_count":31},{"cell_type":"markdown","source":["#2: Support Vector Machine"],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml.classification import LinearSVC\n\n# Load training data\n\n\nlsvc = LinearSVC(maxIter=10, regParam=0.1)\n\n# Fit the model\nlsvcModel = lsvc.fit(trainDF)\n\n# Print the coefficients and intercept for linear SVC\nprint(\"Coefficients: \" + str(lsvcModel.coefficients))\nprint(\"Intercept: \" + str(lsvcModel.intercept))\n\nlsvcresult = lsvcModel.transform(testDF)\nlsvcresult.select(\"prediction\",\"label\",\"features\").show(10)\n\n#Compute accuracy of test\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator\nevaluator = BinaryClassificationEvaluator()\nprint(\"evaluation: %(result)s\" % {\"result\": evaluator.evaluate(lsvcresult)})"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Coefficients: [0.0,-0.033743860875586305,-0.06477774972258915,0.022164113427037852,-0.21179801067761536,-0.08973154033787008,-0.031848486609035116,0.18160775872780818,0.41057161856582985,-0.020728404228870158,-0.11371412081946108,-0.0007163794148134117,-0.13936661024532507,-0.21183712161427687,0.8214301829066173,-0.18376042082601177,-0.10066431671059341,0.7176998228731105,-0.18844295275242354,-0.2015068877965634,-0.16429809707444507,0.2511151567637143,-0.056610560156204186,-0.04462316299942209,-0.048707346508502884,0.16144530315256336,0.18211156078088106,-0.021836216624686284,0.028937469065061516,-0.13243627639627115,-0.10598758156902964,-0.08510144784920891,-0.09982490363582461,-0.21377504173027667,0.09108760494542731,-0.006866516148532331,-0.06506099871283452,0.00420658890194933,0.052301841366817814,-0.046743746808640775,-0.09594057997325951,-0.05034099568580736,0.13807419687463188,-0.09704598123258705,0.02564558935444294,-0.050905492599615146,-0.0459658919972455,-0.12571214711379328,-0.059639479765212486,-6.904500097902799e-05,-0.033895412158631025,0.04561538702473436,-0.13674362251872793,-0.06163674259586478,-0.07935919175859421,-0.02510199498882443,-0.11512791634740474,0.005715799427070747,0.1625257416398855,-0.1316428400068919,-0.059449465963983275,-0.9259984143045604,1.4314481102159486,1.440789220201523,-1.0981018660120525,-1.1701570243335409,0.0,0.0,0.0,0.0,-0.23029300405220185,-0.3343296573856788,-0.671603280514063,-0.5193233994776925,0.6066680991693245,0.2915480126573509,1.2383064015413692,-0.136425999589121,-0.33523425313342764]\nIntercept: -0.009131763063426845\n+----------+-----+--------------------+\nprediction|label|            features|\n+----------+-----+--------------------+\n       0.0|  0.0|(79,[0,5,21,24,38...|\n       0.0|  0.0|(79,[0,5,21,24,38...|\n       0.0|  0.0|(79,[0,5,21,24,38...|\n       0.0|  0.0|(79,[0,5,21,24,38...|\n       0.0|  0.0|(79,[0,5,21,24,38...|\n       0.0|  0.0|(79,[0,5,21,24,38...|\n       0.0|  0.0|(79,[0,5,21,24,38...|\n       0.0|  0.0|(79,[0,5,21,24,38...|\n       0.0|  0.0|(79,[0,5,21,24,38...|\n       0.0|  0.0|(79,[0,5,21,24,38...|\n+----------+-----+--------------------+\nonly showing top 10 rows\n\nevaluation: 0.8901680399851699\n</div>"]}}],"execution_count":33},{"cell_type":"code","source":["from pyspark.ml.evaluation import BinaryClassificationEvaluator\n\n# Let's use the run-of-the-mill evaluator\nsvmevaluator = BinaryClassificationEvaluator()\n\n# We have only two choices: area under ROC and PR curves :-(\nsvmauroc = svmevaluator.evaluate(lsvcresult, {svmevaluator.metricName: \"areaUnderROC\"})\nsvmauprc = svmevaluator.evaluate(lsvcresult, {svmevaluator.metricName: \"areaUnderPR\"})\nprint(\"Area under ROC Curve: {:.4f}\".format(svmauroc))\nprint(\"Area under PR Curve: {:.4f}\".format(svmauprc))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Area under ROC Curve: 0.8902\nArea under PR Curve: 0.7328\n</div>"]}}],"execution_count":34},{"cell_type":"code","source":["#ESTIMATOR\nfrom pyspark.ml.classification import LinearSVC\nlsvm = LinearSVC(featuresCol='features', labelCol='label')\n\n#GRID VECTOR\n\nfrom pyspark.ml.tuning import ParamGridBuilder\nparam_grid_svm = ParamGridBuilder().\\\n      addGrid(lsvm.regParam, [0, 0.1, 0.2, 0.5, 1]).\\\n      addGrid(lsvm.maxIter, [5,10,20,50,100]).\\\n      build()\n\n#Evaluator\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator\nsvmevaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\n\n#CROSS VALIDATION\nfrom pyspark.ml.tuning import CrossValidator\ncv_svm = CrossValidator(estimator=lsvm, evaluator=svmevaluator, estimatorParamMaps=param_grid_svm, numFolds=3)\ncv_svm_model = cv_svm.fit(trainDF)  # fitiing data to my cross validation model\n\nshow_columns = ['features', 'label', 'prediction', 'rawPrediction']\npred_training_svm = cv_svm_model.transform(trainDF)\npred_training_svm.select(show_columns).show(5, truncate=False)\n\npred_test_svm = cv_svm_model.transform(testDF)\npred_test_svm.select(show_columns).show(5, truncate=False)\n\nprint('Support Vector Machine', \"\\n\",'The best RegParam is: ', cv_svm_model.bestModel._java_obj.getRegParam(),  \"\\n\",'The best Iteration is:',cv_svm_model.bestModel._java_obj.getMaxIter() , \"\\n\", 'Area under ROC is:', svmevaluator.evaluate(pred_test_svm, {svmevaluator.metricName: \"areaUnderROC\"}))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">MLlib will automatically track trials in MLflow. After your tuning fit() call has completed, view the MLflow UI to see logged runs.\n+------------------------------------------------------------------------------------------+-----+----------+----------------------------------------+\nfeatures                                                                                  |label|prediction|rawPrediction                           |\n+------------------------------------------------------------------------------------------+-----+----------+----------------------------------------+\n(79,[0,5,21,24,38,44,49,51,56,60,61,70],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])|0.0  |0.0       |[1.5502744362605185,-1.5502744362605185]|\n(79,[0,5,21,24,38,44,49,51,56,60,61,70],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])|0.0  |0.0       |[1.5502744362605185,-1.5502744362605185]|\n(79,[0,5,21,24,38,44,49,51,56,60,61,70],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])|0.0  |0.0       |[1.5502744362605185,-1.5502744362605185]|\n(79,[0,5,21,24,38,44,49,51,56,60,61,70],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])|0.0  |0.0       |[1.5502744362605185,-1.5502744362605185]|\n(79,[0,5,21,24,38,44,49,51,56,60,61,70],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])|0.0  |0.0       |[1.5502744362605185,-1.5502744362605185]|\n+------------------------------------------------------------------------------------------+-----+----------+----------------------------------------+\nonly showing top 5 rows\n\n+------------------------------------------------------------------------------------------+-----+----------+----------------------------------------+\nfeatures                                                                                  |label|prediction|rawPrediction                           |\n+------------------------------------------------------------------------------------------+-----+----------+----------------------------------------+\n(79,[0,5,21,24,38,44,49,51,56,60,61,70],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])|0.0  |0.0       |[1.5502744362605185,-1.5502744362605185]|\n(79,[0,5,21,24,38,44,49,51,56,60,61,70],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])|0.0  |0.0       |[1.5502744362605185,-1.5502744362605185]|\n(79,[0,5,21,24,38,44,49,51,56,60,61,70],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])|0.0  |0.0       |[1.5502744362605185,-1.5502744362605185]|\n(79,[0,5,21,24,38,44,49,51,56,60,61,70],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])|0.0  |0.0       |[1.5502744362605185,-1.5502744362605185]|\n(79,[0,5,21,24,38,44,49,51,56,60,61,70],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])|0.0  |0.0       |[1.5502744362605185,-1.5502744362605185]|\n+------------------------------------------------------------------------------------------+-----+----------+----------------------------------------+\nonly showing top 5 rows\n\nSupport Vector Machine \n The best RegParam is:  0.0 \n The best Iteration is: 100 \n Area under ROC is: 0.9002626996588012\n</div>"]}}],"execution_count":35},{"cell_type":"code","source":["cv_svm_model.avgMetrics"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[47]: [0.8801328381388824,\n 0.8828244764122053,\n 0.8947447206456531,\n 0.8954773556221034,\n 0.8955864451565398,\n 0.8784523672933836,\n 0.8868713845479568,\n 0.8914949066817095,\n 0.892747807622652,\n 0.8929788992054499,\n 0.8777807523155428,\n 0.8861316995036613,\n 0.8896649122764579,\n 0.891711302239333,\n 0.8917845460874403,\n 0.8796245103946323,\n 0.8861596714201143,\n 0.8873581874206293,\n 0.8884618773905053,\n 0.8887571520509476,\n 0.8794383172044258,\n 0.8831719989651949,\n 0.8860843878457356,\n 0.8875743412838755,\n 0.887648780327474]</div>"]}}],"execution_count":36},{"cell_type":"markdown","source":["#3: Naive Bayes"],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml.classification import NaiveBayes\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator\n\n# create the trainer and set its parameters\nnb = NaiveBayes(smoothing=1.0, modelType=\"multinomial\")\n\n# train the model\nnbmodel = nb.fit(trainDF)\n\n# select example rows to display.\nnbresult = model.transform(testDF)\nnbresult.select(\"prediction\",\"label\",\"features\").show(10)\n\n# compute accuracy on the test set\nnbevaluator = BinaryClassificationEvaluator()\naccuracy = nbevaluator.evaluate(nbresult)\nprint(\"evaluations: %(nbresult)s\" % {\"nbresult\": nbevaluator.evaluate(nbresult)})"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----------+-----+--------------------+\nprediction|label|            features|\n+----------+-----+--------------------+\n       0.0|  0.0|(79,[0,5,21,24,38...|\n       0.0|  0.0|(79,[0,5,21,24,38...|\n       0.0|  0.0|(79,[0,5,21,24,38...|\n       0.0|  0.0|(79,[0,5,21,24,38...|\n       0.0|  0.0|(79,[0,5,21,24,38...|\n       0.0|  0.0|(79,[0,5,21,24,38...|\n       0.0|  0.0|(79,[0,5,21,24,38...|\n       0.0|  0.0|(79,[0,5,21,24,38...|\n       0.0|  0.0|(79,[0,5,21,24,38...|\n       0.0|  0.0|(79,[0,5,21,24,38...|\n+----------+-----+--------------------+\nonly showing top 10 rows\n\nevaluations: 0.9035111044157295\n</div>"]}}],"execution_count":38},{"cell_type":"code","source":["from pyspark.ml.evaluation import BinaryClassificationEvaluator\n\n# Let's use the run-of-the-mill evaluator\nnbevaluator = BinaryClassificationEvaluator()\n\n# We have only two choices: area under ROC and PR curves :-(\nnbauroc = nbevaluator.evaluate(nbresult, {nbevaluator.metricName: \"areaUnderROC\"})\nnbauprc = nbevaluator.evaluate(nbresult, {nbevaluator.metricName: \"areaUnderPR\"})\nprint(\"Area under ROC Curve: {:.4f}\".format(nbauroc))\nprint(\"Area under PR Curve: {:.4f}\".format(nbauprc))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Area under ROC Curve: 0.9035\nArea under PR Curve: 0.7582\n</div>"]}}],"execution_count":39},{"cell_type":"code","source":["#ESTIMATOR\nfrom pyspark.ml.classification import NaiveBayes\nnb = NaiveBayes(featuresCol='features', labelCol='label')\n\n#GRID VECTOR\n\nfrom pyspark.ml.tuning import ParamGridBuilder\nparam_grid_nb = ParamGridBuilder().\\\n      addGrid(nb.smoothing, [0.0,1.0,2.0,4.0,6.0,8.0]).\\\n      addGrid(nb.modelType, [\"multinomial\", \"bernoulli\"]).\\\n      build()\n\n#Evaluator\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator\nnbevaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\n\n#CROSS VALIDATION\nfrom pyspark.ml.tuning import CrossValidator\ncv_nb = CrossValidator(estimator=nb, evaluator=nbevaluator, estimatorParamMaps=param_grid_nb, numFolds=3)\ncv_nb_model = cv_nb.fit(trainDF)  # fitiing data to my cross validation model\n\nshow_columns = ['features', 'label', 'prediction', 'rawPrediction', 'probability']\npred_training_nb = cv_nb_model.transform(trainDF)\npred_training_nb.select(show_columns).show(5, truncate=False)\n\npred_test_nb = cv_nb_model.transform(testDF)\npred_test_nb.select(show_columns).show(5, truncate=False)\n\nprint('Naive Bayes ',\"\\n\",'The best Smoothening is: ', cv_nb_model.bestModel._java_obj.getSmoothing(), \"\\n\",'The best model type is:', cv_nb_model.bestModel._java_obj.getModelType(), \"\\n\", 'Area under ROC is:', nbevaluator.evaluate(pred_test_nb, {nbevaluator.metricName: \"areaUnderROC\"}))\ncv_nb_model.avgMetrics\n\n##nbauroc = nbevaluator.evaluate(nbresult, {pred_test_nb.metricName: \"areaUnderROC\"})\n#nbauprc = nbevaluator.evaluate(nbresult, {pred_test_nb.metricName: \"areaUnderPR\"})\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">MLlib will automatically track trials in MLflow. After your tuning fit() call has completed, view the MLflow UI to see logged runs.\n+------------------------------------------------------------------------------------------+-----+----------+---------------------------------------+---------------------------------------+\nfeatures                                                                                  |label|prediction|rawPrediction                          |probability                            |\n+------------------------------------------------------------------------------------------+-----+----------+---------------------------------------+---------------------------------------+\n(79,[0,5,21,24,38,44,49,51,56,60,61,70],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])|0.0  |0.0       |[-37.50684453802806,-39.10566176696517]|[0.8318530116420073,0.1681469883579927]|\n(79,[0,5,21,24,38,44,49,51,56,60,61,70],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])|0.0  |0.0       |[-37.50684453802806,-39.10566176696517]|[0.8318530116420073,0.1681469883579927]|\n(79,[0,5,21,24,38,44,49,51,56,60,61,70],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])|0.0  |0.0       |[-37.50684453802806,-39.10566176696517]|[0.8318530116420073,0.1681469883579927]|\n(79,[0,5,21,24,38,44,49,51,56,60,61,70],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])|0.0  |0.0       |[-37.50684453802806,-39.10566176696517]|[0.8318530116420073,0.1681469883579927]|\n(79,[0,5,21,24,38,44,49,51,56,60,61,70],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])|0.0  |0.0       |[-37.50684453802806,-39.10566176696517]|[0.8318530116420073,0.1681469883579927]|\n+------------------------------------------------------------------------------------------+-----+----------+---------------------------------------+---------------------------------------+\nonly showing top 5 rows\n\n+------------------------------------------------------------------------------------------+-----+----------+---------------------------------------+---------------------------------------+\nfeatures                                                                                  |label|prediction|rawPrediction                          |probability                            |\n+------------------------------------------------------------------------------------------+-----+----------+---------------------------------------+---------------------------------------+\n(79,[0,5,21,24,38,44,49,51,56,60,61,70],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])|0.0  |0.0       |[-37.50684453802806,-39.10566176696517]|[0.8318530116420073,0.1681469883579927]|\n(79,[0,5,21,24,38,44,49,51,56,60,61,70],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])|0.0  |0.0       |[-37.50684453802806,-39.10566176696517]|[0.8318530116420073,0.1681469883579927]|\n(79,[0,5,21,24,38,44,49,51,56,60,61,70],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])|0.0  |0.0       |[-37.50684453802806,-39.10566176696517]|[0.8318530116420073,0.1681469883579927]|\n(79,[0,5,21,24,38,44,49,51,56,60,61,70],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])|0.0  |0.0       |[-37.50684453802806,-39.10566176696517]|[0.8318530116420073,0.1681469883579927]|\n(79,[0,5,21,24,38,44,49,51,56,60,61,70],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])|0.0  |0.0       |[-37.50684453802806,-39.10566176696517]|[0.8318530116420073,0.1681469883579927]|\n+------------------------------------------------------------------------------------------+-----+----------+---------------------------------------+---------------------------------------+\nonly showing top 5 rows\n\nNaive Bayes  \n The best Smoothening is:  0.0 \n The best model type is: multinomial \n Area under ROC is: 0.8008644664305177\n</div>"]}}],"execution_count":40},{"cell_type":"code","source":["cv_nb_model.avgMetrics"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[46]: [0.7967954044240257,\n 0.773598523269748,\n 0.7967271715887003,\n 0.7734518898564935,\n 0.7966523254479954,\n 0.7733613277827187,\n 0.7965258818135919,\n 0.7731625370724926,\n 0.7963875324863571,\n 0.7729787503336294,\n 0.7962399754722813,\n 0.7727947994406505]</div>"]}}],"execution_count":41},{"cell_type":"markdown","source":["# Random Forest"],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml.classification import RandomForestClassifier\n\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator\n\n# Train a RandomForest model.\nrf = RandomForestClassifier( numTrees=10)\n\n\n# Train model.  This also runs the indexers.\nrfmodel = rf.fit(trainDF)\n\n# Make predictions.\nrfresult = rfmodel.transform(testDF)\n\n# Select example rows to display.\nrfresult.select(\"prediction\",\"label\",\"features\").show(10)\n\n# Select (prediction, true label) and compute test error\nrfevaluator = BinaryClassificationEvaluator()\nprint(\"evaluations: %(rfresult)s\" % {\"rfresult\": rfevaluator.evaluate(rfresult)})\n\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----------+-----+--------------------+\nprediction|label|            features|\n+----------+-----+--------------------+\n       0.0|  0.0|(79,[0,5,21,24,38...|\n       0.0|  0.0|(79,[0,5,21,24,38...|\n       0.0|  0.0|(79,[0,5,21,24,38...|\n       0.0|  0.0|(79,[0,5,21,24,38...|\n       0.0|  0.0|(79,[0,5,21,24,38...|\n       0.0|  0.0|(79,[0,5,21,24,38...|\n       0.0|  0.0|(79,[0,5,21,24,38...|\n       0.0|  0.0|(79,[0,5,21,24,38...|\n       0.0|  0.0|(79,[0,5,21,24,38...|\n       0.0|  0.0|(79,[0,5,21,24,38...|\n+----------+-----+--------------------+\nonly showing top 10 rows\n\nevaluations: 0.8702890701845087\n</div>"]}}],"execution_count":43},{"cell_type":"code","source":["# We have only two choices: area under ROC and PR curves :-(\nrfauroc = rfevaluator.evaluate(rfresult, {rfevaluator.metricName: \"areaUnderROC\"})\nrfauprc = rfevaluator.evaluate(rfresult, {rfevaluator.metricName: \"areaUnderPR\"})\nprint(\"Area under ROC Curve: {:.4f}\".format(rfauroc))\nprint(\"Area under PR Curve: {:.4f}\".format(rfauprc))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Area under ROC Curve: 0.8703\nArea under PR Curve: 0.6924\n</div>"]}}],"execution_count":44},{"cell_type":"code","source":["#ESTIMATOR\nfrom pyspark.ml.classification import RandomForestClassifier\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator\n\n# Train a RandomForest model.\nrf = RandomForestClassifier(featuresCol='features', labelCol='label')\n\n#GRID VECTOR\nfrom pyspark.ml.tuning import ParamGridBuilder\nparam_grid_rf = ParamGridBuilder().\\\n      addGrid(rf.impurity,['gini']).\\\n      addGrid(rf.maxDepth, [2, 3, 4]).\\\n      addGrid(rf.minInfoGain, [0.0, 0.1, 0.2, 0.3]).\\\n      addGrid(rf.numTrees,[20,40,60,80,100]).\\\n      build()\n\n#Evaluator\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator\nrfevaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\n\n#CROSS VALIDATION\nfrom pyspark.ml.tuning import CrossValidator\ncv_rf = CrossValidator(estimator=rf, evaluator=rfevaluator, estimatorParamMaps=param_grid_rf, numFolds=3)\ncv_rf_model = cv_rf.fit(trainDF)  # fitiing data to my cross validation model\n\nshow_columns = ['features', 'label', 'prediction', 'rawPrediction', 'probability']\npred_training_rf = cv_rf_model.transform(trainDF)\npred_training_rf.select(show_columns).show(5, truncate=False)\n\npred_test_rf = cv_rf_model.transform(testDF)\npred_test_rf.select(show_columns).show(5, truncate=False)\n\nprint('Random forest ',\"\\n\",'The best Max Depth is: ', cv_rf_model.bestModel._java_obj.getMaxDepth(), \"\\n\",'The best min Info gain is:', cv_rf_model.bestModel._java_obj.getMinInfoGain(), \"\\n\", 'Area under ROC is:', rfevaluator.evaluate(pred_test_rf, {rfevaluator.metricName: \"areaUnderROC\"}))\n#rfmodel.trees\n##nbauroc = rfevaluator.evaluate(pred_test_rf, {rfevaluator.metricName: \"areaUnderROC\"})\n#nbauprc = rfevaluator.evaluate(pred_test_rf, {rfevaluator.metricName: \"areaUnderPR\"})"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">MLlib will automatically track trials in MLflow. After your tuning fit() call has completed, view the MLflow UI to see logged runs.\n+------------------------------------------------------------------------------------------+-----+----------+---------------------------------------+---------------------------------------+\nfeatures                                                                                  |label|prediction|rawPrediction                          |probability                            |\n+------------------------------------------------------------------------------------------+-----+----------+---------------------------------------+---------------------------------------+\n(79,[0,5,21,24,38,44,49,51,56,60,61,70],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])|0.0  |0.0       |[43.220331569424246,16.779668430575736]|[0.7203388594904043,0.2796611405095957]|\n(79,[0,5,21,24,38,44,49,51,56,60,61,70],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])|0.0  |0.0       |[43.220331569424246,16.779668430575736]|[0.7203388594904043,0.2796611405095957]|\n(79,[0,5,21,24,38,44,49,51,56,60,61,70],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])|0.0  |0.0       |[43.220331569424246,16.779668430575736]|[0.7203388594904043,0.2796611405095957]|\n(79,[0,5,21,24,38,44,49,51,56,60,61,70],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])|0.0  |0.0       |[43.220331569424246,16.779668430575736]|[0.7203388594904043,0.2796611405095957]|\n(79,[0,5,21,24,38,44,49,51,56,60,61,70],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])|0.0  |0.0       |[43.220331569424246,16.779668430575736]|[0.7203388594904043,0.2796611405095957]|\n+------------------------------------------------------------------------------------------+-----+----------+---------------------------------------+---------------------------------------+\nonly showing top 5 rows\n\n+------------------------------------------------------------------------------------------+-----+----------+---------------------------------------+---------------------------------------+\nfeatures                                                                                  |label|prediction|rawPrediction                          |probability                            |\n+------------------------------------------------------------------------------------------+-----+----------+---------------------------------------+---------------------------------------+\n(79,[0,5,21,24,38,44,49,51,56,60,61,70],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])|0.0  |0.0       |[43.220331569424246,16.779668430575736]|[0.7203388594904043,0.2796611405095957]|\n(79,[0,5,21,24,38,44,49,51,56,60,61,70],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])|0.0  |0.0       |[43.220331569424246,16.779668430575736]|[0.7203388594904043,0.2796611405095957]|\n(79,[0,5,21,24,38,44,49,51,56,60,61,70],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])|0.0  |0.0       |[43.220331569424246,16.779668430575736]|[0.7203388594904043,0.2796611405095957]|\n(79,[0,5,21,24,38,44,49,51,56,60,61,70],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])|0.0  |0.0       |[43.220331569424246,16.779668430575736]|[0.7203388594904043,0.2796611405095957]|\n(79,[0,5,21,24,38,44,49,51,56,60,61,70],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])|0.0  |0.0       |[43.220331569424246,16.779668430575736]|[0.7203388594904043,0.2796611405095957]|\n+------------------------------------------------------------------------------------------+-----+----------+---------------------------------------+---------------------------------------+\nonly showing top 5 rows\n\nRandom forest  \n The best Max Depth is:  4 \n The best min Info gain is: 0.0 \n Area under ROC is: 0.8784316766552892\n</div>"]}}],"execution_count":45},{"cell_type":"code","source":["cv_rf_model.avgMetrics"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[63]: [0.8467468727815348,\n 0.856713290801483,\n 0.8643139645545602,\n 0.8606172339432743,\n 0.8603757437411175,\n 0.5,\n 0.5,\n 0.5,\n 0.5,\n 0.5,\n 0.5,\n 0.5,\n 0.5,\n 0.5,\n 0.5,\n 0.5,\n 0.5,\n 0.5,\n 0.5,\n 0.5,\n 0.8579541318497603,\n 0.8607442834777863,\n 0.8648662126361153,\n 0.8635001870314647,\n 0.864399495971802,\n 0.5,\n 0.5,\n 0.5,\n 0.5,\n 0.5,\n 0.5,\n 0.5,\n 0.5,\n 0.5,\n 0.5,\n 0.5,\n 0.5,\n 0.5,\n 0.5,\n 0.5,\n 0.8688613431282997,\n 0.8679062517913052,\n 0.8730238428321284,\n 0.8694100473342277,\n 0.8710812800892465,\n 0.5,\n 0.5,\n 0.5,\n 0.5,\n 0.5,\n 0.5,\n 0.5,\n 0.5,\n 0.5,\n 0.5,\n 0.5,\n 0.5,\n 0.5,\n 0.5,\n 0.5]</div>"]}}],"execution_count":46},{"cell_type":"markdown","source":["#5: Gradient Boost"],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml.classification import GBTClassifier\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator\n\n# Train a GBT model.\ngb = GBTClassifier()\n# Chain indexers and GBT in a Pipeline\n\n# Train model.  This also runs the indexers.\ngbmodel = gb.fit(trainDF)\n\n# Make predictions.\ngbresult = gbmodel.transform(testDF)\n\n# Select example rows to display.\ngbresult.select(\"prediction\",\"label\",\"features\").show(5)\n\n# Select (prediction, true label) and compute test error\ngbevaluator = BinaryClassificationEvaluator()\n\nprint(\"evaluations: %(gbresult)s\" % {\"gbresult\": gbevaluator.evaluate(gbresult)})\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----------+-----+--------------------+\nprediction|label|            features|\n+----------+-----+--------------------+\n       0.0|  0.0|(79,[0,5,21,24,38...|\n       0.0|  0.0|(79,[0,5,21,24,38...|\n       0.0|  0.0|(79,[0,5,21,24,38...|\n       0.0|  0.0|(79,[0,5,21,24,38...|\n       0.0|  0.0|(79,[0,5,21,24,38...|\n+----------+-----+--------------------+\nonly showing top 5 rows\n\nevaluations: 0.8976359609165223\n</div>"]}}],"execution_count":48},{"cell_type":"code","source":["# We have only two choices: area under ROC and PR curves :-(\ngbauroc = gbevaluator.evaluate(gbresult, {gbevaluator.metricName: \"areaUnderROC\"})\ngbauprc = gbevaluator.evaluate(gbresult, {gbevaluator.metricName: \"areaUnderPR\"})\nprint(\"Area under ROC Curve: {:.4f}\".format(gbauroc))\nprint(\"Area under PR Curve: {:.4f}\".format(gbauprc))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Area under ROC Curve: 0.8976\nArea under PR Curve: 0.7440\n</div>"]}}],"execution_count":49},{"cell_type":"code","source":["from pyspark.ml.classification import GBTClassifier\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator\n\n# ESTIMATOR\ngbt = GBTClassifier(featuresCol='features', labelCol='label')\n\n\n#GRID VECTOR\nfrom pyspark.ml.tuning import ParamGridBuilder\nparam_grid_gbt = ParamGridBuilder().\\\n    addGrid(gbt.maxDepth, [2, 3, 4]).\\\n    addGrid(gbt.minInfoGain, [0.0, 0.1, 0.2]).\\\n    addGrid(gbt.stepSize, [0.02, 0.05, 0.1]).\\\n    addGrid(gb.maxIter,[20,40,60,80,100]).\\\n    build()\n\n#Evaluator\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator\ngbtevaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\n\n#CROSS VALIDATION\nfrom pyspark.ml.tuning import CrossValidator\ncv_gbt = CrossValidator(estimator=gbt, evaluator=gbtevaluator, estimatorParamMaps=param_grid_gbt)\ncv_gbt_model = cv_gbt.fit(trainDF)  # fitiing data to my cross validation model\n\nshow_columns = ['features', 'label', 'prediction', 'rawPrediction', 'probability']\npred_training_gbt = cv_gbt_model.transform(trainDF)\npred_training_gbt.select(show_columns).show(5, truncate=False)\n\npred_test_gbt = cv_gbt_model.transform(testDF)\npred_test_gbt.select(show_columns).show(5, truncate=False)\n\n\nprint('Gradient Boosting ',\"\\n\",'The best Max Depth is: ', cv_gbt_model.bestModel._java_obj.getMaxDepth(), \"\\n\",'The best min Info gain is:',cv_gbt_model.bestModel._java_obj.getMinInfoGain(), \"\\n\", 'step size: ', cv_gbt_model.bestModel._java_obj.getStepSize(),\"\\n\" ,'Area under ROC is:', gbtevaluator.evaluate(pred_test_gbt, {gbtevaluator.metricName: \"areaUnderROC\"}))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">MLlib will automatically track trials in MLflow. After your tuning fit() call has completed, view the MLflow UI to see logged runs.\n+------------------------------------------------------------------------------------------+-----+----------+----------------------------------------+---------------------------------------+\nfeatures                                                                                  |label|prediction|rawPrediction                           |probability                            |\n+------------------------------------------------------------------------------------------+-----+----------+----------------------------------------+---------------------------------------+\n(79,[0,5,21,24,38,44,49,51,56,60,61,70],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])|0.0  |0.0       |[0.8386282111334181,-0.8386282111334181]|[0.842540894325519,0.15745910567448096]|\n(79,[0,5,21,24,38,44,49,51,56,60,61,70],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])|0.0  |0.0       |[0.8386282111334181,-0.8386282111334181]|[0.842540894325519,0.15745910567448096]|\n(79,[0,5,21,24,38,44,49,51,56,60,61,70],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])|0.0  |0.0       |[0.8386282111334181,-0.8386282111334181]|[0.842540894325519,0.15745910567448096]|\n(79,[0,5,21,24,38,44,49,51,56,60,61,70],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])|0.0  |0.0       |[0.8386282111334181,-0.8386282111334181]|[0.842540894325519,0.15745910567448096]|\n(79,[0,5,21,24,38,44,49,51,56,60,61,70],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])|0.0  |0.0       |[0.8386282111334181,-0.8386282111334181]|[0.842540894325519,0.15745910567448096]|\n+------------------------------------------------------------------------------------------+-----+----------+----------------------------------------+---------------------------------------+\nonly showing top 5 rows\n\n+------------------------------------------------------------------------------------------+-----+----------+----------------------------------------+---------------------------------------+\nfeatures                                                                                  |label|prediction|rawPrediction                           |probability                            |\n+------------------------------------------------------------------------------------------+-----+----------+----------------------------------------+---------------------------------------+\n(79,[0,5,21,24,38,44,49,51,56,60,61,70],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])|0.0  |0.0       |[0.8386282111334181,-0.8386282111334181]|[0.842540894325519,0.15745910567448096]|\n(79,[0,5,21,24,38,44,49,51,56,60,61,70],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])|0.0  |0.0       |[0.8386282111334181,-0.8386282111334181]|[0.842540894325519,0.15745910567448096]|\n(79,[0,5,21,24,38,44,49,51,56,60,61,70],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])|0.0  |0.0       |[0.8386282111334181,-0.8386282111334181]|[0.842540894325519,0.15745910567448096]|\n(79,[0,5,21,24,38,44,49,51,56,60,61,70],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])|0.0  |0.0       |[0.8386282111334181,-0.8386282111334181]|[0.842540894325519,0.15745910567448096]|\n(79,[0,5,21,24,38,44,49,51,56,60,61,70],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])|0.0  |0.0       |[0.8386282111334181,-0.8386282111334181]|[0.842540894325519,0.15745910567448096]|\n+------------------------------------------------------------------------------------------+-----+----------+----------------------------------------+---------------------------------------+\nonly showing top 5 rows\n\nGradient Boosting  \n The best Max Depth is:  4 \n The best min Info gain is: 0.0 \n step size:  0.1 \n Area under ROC is: 0.8934300783341733\n</div>"]}}],"execution_count":50},{"cell_type":"code","source":["cv_gbt_model.avgMetrics"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[66]: [0.8633184252847457,\n 0.8633184252847457,\n 0.8633184252847457,\n 0.8633184252847457,\n 0.8633184252847457,\n 0.8703695893815853,\n 0.8703695893815853,\n 0.8703695893815853,\n 0.8703695893815853,\n 0.8703695893815853,\n 0.8783545444129885,\n 0.8783545444129885,\n 0.8783545444129885,\n 0.8783545444129885,\n 0.8783545444129885,\n 0.7733662923002798,\n 0.7733662923002796,\n 0.7733662923002798,\n 0.7733662923002798,\n 0.7733662923002798,\n 0.7733662923002798,\n 0.7733662923002798,\n 0.7733662923002798,\n 0.7733662923002798,\n 0.7733662923002798,\n 0.7733662923002796,\n 0.7733662923002798,\n 0.7733662923002796,\n 0.7733662923002798,\n 0.7733662923002798,\n 0.7657333932614926,\n 0.7657333932614926,\n 0.7657333932614926,\n 0.7657333932614926,\n 0.7657333932614926,\n 0.7614759892049279,\n 0.7614759892049279,\n 0.7614759892049279,\n 0.7614759892049279,\n 0.7614759892049279,\n 0.7614759892049279,\n 0.7614759892049279,\n 0.7614759892049279,\n 0.7614759892049279,\n 0.7614759892049279,\n 0.8639792398741235,\n 0.8639792398741235,\n 0.8639792398741235,\n 0.8639792398741235,\n 0.8639792398741235,\n 0.8776569992792966,\n 0.8776569992792966,\n 0.8776569992792966,\n 0.8776569992792966,\n 0.8776569992792966,\n 0.8849526633636242,\n 0.884952663363624,\n 0.884952663363624,\n 0.884952663363624,\n 0.884952663363624,\n 0.7733849986477823,\n 0.7733849986477823,\n 0.7733849986477823,\n 0.7733849986477823,\n 0.7733849986477823,\n 0.7733849986477823,\n 0.7733849986477823,\n 0.7733849986477823,\n 0.7733849986477823,\n 0.7733849986477823,\n 0.7733849986477823,\n 0.7733849986477823,\n 0.7733849986477823,\n 0.7733849986477823,\n 0.7733849986477823,\n 0.7657338537669935,\n 0.7657338537669935,\n 0.7657338537669935,\n 0.7657338537669935,\n 0.7657338537669935,\n 0.7614807600419176,\n 0.7614807600419176,\n 0.7614807600419176,\n 0.7614807600419176,\n 0.7614807600419176,\n 0.7614807600419176,\n 0.7614807600419176,\n 0.7614807600419176,\n 0.7614807600419176,\n 0.7614807600419176,\n 0.8753456964845252,\n 0.8753456964845252,\n 0.8753456964845252,\n 0.8753456964845252,\n 0.8753456964845252,\n 0.8825082186398436,\n 0.8825082186398439,\n 0.8825082186398436,\n 0.8825082186398434,\n 0.8825082186398436,\n 0.8897826543415988,\n 0.8897826543415985,\n 0.889782654341599,\n 0.8897826543415989,\n 0.8897826543415988,\n 0.7733849986477823,\n 0.7733849986477823,\n 0.7733849986477823,\n 0.7733849986477823,\n 0.7733849986477823,\n 0.7733849986477823,\n 0.7733849986477823,\n 0.7733849986477823,\n 0.7733849986477823,\n 0.7733849986477823,\n 0.7733849986477823,\n 0.7733849986477823,\n 0.7733849986477823,\n 0.7733849986477823,\n 0.7733849986477823,\n 0.7657338537669935,\n 0.7657338537669935,\n 0.7657338537669935,\n 0.7657338537669935,\n 0.7657338537669935,\n 0.7614807600419176,\n 0.7614807600419176,\n 0.7614807600419176,\n 0.7614807600419176,\n 0.7614807600419176,\n 0.7614807600419176,\n 0.7614807600419176,\n 0.7614807600419176,\n 0.7614807600419176,\n 0.7614807600419176]</div>"]}}],"execution_count":51},{"cell_type":"code","source":["from pyspark.mllib.evaluation import MulticlassMetrics\nscoreandlabels = gbresult.rdd.map(lambda z: (z[\"label\"], z[\"prediction\"]))\nmetric = MulticlassMetrics(scoreandlabels)\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":52},{"cell_type":"code","source":["#model_stages = cv + cv_svm + cv_nb+cv_rf +cv_gbt\n#pipelined_models = Pipeline(stages= model_stages).fit(trainDF)\n#pipelined_result = pipelined_models.transform(testDF)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":53},{"cell_type":"markdown","source":["#MODEL ACCURACY \n(on training data)"],"metadata":{}},{"cell_type":"code","source":["print('Models and their Performance',\"\\n\")\nprint('Logistic Regression',evaluator.evaluate(pred_training_cv, {evaluator.metricName: \"areaUnderROC\"}))\nprint('Support Vector Machine',svmevaluator.evaluate(pred_training_svm, {svmevaluator.metricName: \"areaUnderROC\"}))\nprint('Naive Bayes', nbevaluator.evaluate(pred_training_nb, {nbevaluator.metricName: \"areaUnderROC\"}))\nprint('Random forest', rfevaluator.evaluate(pred_training_rf, {rfevaluator.metricName: \"areaUnderROC\"}))\nprint('Gradient Boost', gbtevaluator.evaluate(pred_training_gbt, {gbtevaluator.metricName: \"areaUnderROC\"}))\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Models and their Performance \n\nLogistic Regression 0.9018785721227884\nSupport Vector Machine 0.8967160185508454\nNaive Bayes 0.7971001963021456\nRandom forest 0.875723801543902\nGradient Boost 0.8921736262323415\n</div>"]}}],"execution_count":55},{"cell_type":"markdown","source":["#MODEL PREDICTION ACCURACY\n(on test data)"],"metadata":{}},{"cell_type":"code","source":["print('Models and their Performance',\"\\n\")\nprint('Logistic Regression',evaluator.evaluate(pred_test_cv, {evaluator.metricName: \"areaUnderROC\"}))\nprint('Support Vector Machine',svmevaluator.evaluate(pred_test_svm, {svmevaluator.metricName: \"areaUnderROC\"}))\nprint('Naive Bayes', nbevaluator.evaluate(pred_test_nb, {nbevaluator.metricName: \"areaUnderROC\"}))\nprint('Random forest', rfevaluator.evaluate(pred_test_rf, {rfevaluator.metricName: \"areaUnderROC\"}))\nprint('Gradient Boost', gbtevaluator.evaluate(pred_test_gbt, {gbtevaluator.metricName: \"areaUnderROC\"}))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Models and their Performance \n\nLogistic Regression 0.9060457277769502\nSupport Vector Machine 0.9002626996588036\nNaive Bayes 0.8008644664305182\nRandom forest 0.8784316766552883\nGradient Boost 0.8934300783341731\n</div>"]}}],"execution_count":57},{"cell_type":"markdown","source":["#ROC V/S PR"],"metadata":{}},{"cell_type":"code","source":["print('Models and their Performance',\"\\n\")\nprint('Logistic Regression: ROC: ',evaluator.evaluate(pred_training_cv, {evaluator.metricName: \"areaUnderROC\"}), ', PR: ',evaluator.evaluate(pred_training_cv, {evaluator.metricName: \"areaUnderPR\"}))\nprint('Support Vector Machine',svmevaluator.evaluate(pred_training_svm, {svmevaluator.metricName: \"areaUnderROC\"}), ', PR: ',svmevaluator.evaluate(pred_training_svm, {svmevaluator.metricName: \"areaUnderPR\"}))\nprint('Naive Bayes', nbevaluator.evaluate(pred_training_nb, {nbevaluator.metricName: \"areaUnderROC\"}),', PR: ' , nbevaluator.evaluate(pred_training_nb, {nbevaluator.metricName: \"areaUnderPR\"}))\nprint('Random forest', rfevaluator.evaluate(pred_training_rf, {rfevaluator.metricName: \"areaUnderROC\"}), ', PR: ', rfevaluator.evaluate(pred_training_rf, {rfevaluator.metricName: \"areaUnderPR\"}))\nprint('Gradient Boost', gbtevaluator.evaluate(pred_training_gbt, {gbtevaluator.metricName: \"areaUnderROC\"}),', PR: ' , gbtevaluator.evaluate(pred_training_gbt ,{gbtevaluator.metricName: \"areaUnderPR\"}))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Models and their Performance \n\nLogistic Regression: ROC:  0.901878572122784 , PR:  0.7681686474339882\nSupport Vector Machine 0.8967160185508478 , PR:  0.7597095009407047\nNaive Bayes 0.7971001963021511 , PR:  0.53013090623475\nRandom forest 0.8757238015439036 , PR:  0.7187400976812648\nGradient Boost 0.8921736262323415 , PR:  0.749006745002413\n</div>"]}}],"execution_count":59},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":60}],"metadata":{"name":"Clean_census","notebookId":333901826162333},"nbformat":4,"nbformat_minor":0}
